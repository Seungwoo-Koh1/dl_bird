{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bd689b2a419749beb53266385cb74125": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_512653525f4244799667304be48104e6",
              "IPY_MODEL_fccfbedb6177454fbde89b74cdfef38e",
              "IPY_MODEL_234e1cca4cbe422aa7a83e907c242cbe"
            ],
            "layout": "IPY_MODEL_91ae20cb50e444f5bf4c208116f406f4"
          }
        },
        "512653525f4244799667304be48104e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a16518160244ac5bf2030dca2c9b6ff",
            "placeholder": "​",
            "style": "IPY_MODEL_5cfb3bff9f8e4974911e328d9d07d09d",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "fccfbedb6177454fbde89b74cdfef38e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_179f17a7573e4d9c8999a9066387b50b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea69c94d529044f29084fb1edee34cec",
            "value": 2
          }
        },
        "234e1cca4cbe422aa7a83e907c242cbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c76db074928648e49f38792380d8a4ac",
            "placeholder": "​",
            "style": "IPY_MODEL_a2fac5e3d6c24d27a4311ac367a62cd7",
            "value": " 2/2 [00:10&lt;00:00,  0.20it/s]"
          }
        },
        "91ae20cb50e444f5bf4c208116f406f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "2a16518160244ac5bf2030dca2c9b6ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cfb3bff9f8e4974911e328d9d07d09d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "179f17a7573e4d9c8999a9066387b50b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea69c94d529044f29084fb1edee34cec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c76db074928648e49f38792380d8a4ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2fac5e3d6c24d27a4311ac367a62cd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0c5ffb124f44a3aa9ad60232092c6c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a3cd2f4f3434a0ab5dd97d232dbd8dd",
              "IPY_MODEL_b0e7d78ec46646cbb6ac96b7bbfe7aba",
              "IPY_MODEL_ad1c79a43fad40638ff2cd9f8429c34a"
            ],
            "layout": "IPY_MODEL_a66484ab139a40cab28786cbdb368bc2"
          }
        },
        "8a3cd2f4f3434a0ab5dd97d232dbd8dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0baf674906c34cfa8424ddf681742fce",
            "placeholder": "​",
            "style": "IPY_MODEL_3f98060dcdbf4554aa575128144e3295",
            "value": "Epoch 0:   3%"
          }
        },
        "b0e7d78ec46646cbb6ac96b7bbfe7aba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4332e40256b34cd199a25f5c036c369e",
            "max": 792,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e50f93e01b7248f4bb96d579c4a1a321",
            "value": 20
          }
        },
        "ad1c79a43fad40638ff2cd9f8429c34a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96722a63eb2c44ae92767385bd16e3dc",
            "placeholder": "​",
            "style": "IPY_MODEL_6c0c787ed9514ca2ad7cce06198c7ad5",
            "value": " 20/792 [02:41&lt;1:43:53,  0.12it/s, v_num=0]"
          }
        },
        "a66484ab139a40cab28786cbdb368bc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "0baf674906c34cfa8424ddf681742fce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f98060dcdbf4554aa575128144e3295": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4332e40256b34cd199a25f5c036c369e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e50f93e01b7248f4bb96d579c4a1a321": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96722a63eb2c44ae92767385bd16e3dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c0c787ed9514ca2ad7cce06198c7ad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2592f34d027d46218a6563a381fe6f29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd3dd174cca34b1faba5ed8544626386",
              "IPY_MODEL_ec0bb50b94f643b9828fc140a284ba35",
              "IPY_MODEL_34333efbab8347f9bfc9dc42dd8c593e"
            ],
            "layout": "IPY_MODEL_3a2c5717eeaf41eeac4d2a1ead92f47e"
          }
        },
        "bd3dd174cca34b1faba5ed8544626386": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6fcedb25e8a4df3b7cc3c3609651559",
            "placeholder": "​",
            "style": "IPY_MODEL_d3502610024a4f2bb134664946bfde08",
            "value": "Predicting: "
          }
        },
        "ec0bb50b94f643b9828fc140a284ba35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29c05e8784ea45919321ff3286e37df4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_917fbcbb5e5e4d1ca250448f3a0d0d39",
            "value": 0
          }
        },
        "34333efbab8347f9bfc9dc42dd8c593e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56321910255d4eab96176542cd7db2d4",
            "placeholder": "​",
            "style": "IPY_MODEL_8ace51d4a416454dae652940f309c111",
            "value": " 0/? [00:00&lt;?, ?it/s]"
          }
        },
        "3a2c5717eeaf41eeac4d2a1ead92f47e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "f6fcedb25e8a4df3b7cc3c3609651559": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3502610024a4f2bb134664946bfde08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29c05e8784ea45919321ff3286e37df4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "917fbcbb5e5e4d1ca250448f3a0d0d39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56321910255d4eab96176542cd7db2d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ace51d4a416454dae652940f309c111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cced864c51f48a7a0268cd83db9710b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7387fbd601d34ad1aa36b098c195dbc1",
              "IPY_MODEL_53f3fc3f9a7a4472b3e8419ef54c14d9",
              "IPY_MODEL_3b8c5c80f70f421fbe4fa27e368fc328"
            ],
            "layout": "IPY_MODEL_9491b9312268405393632ff4416848a4"
          }
        },
        "7387fbd601d34ad1aa36b098c195dbc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35e2c3b6414d4bc6b2e50d12b3b9ffc7",
            "placeholder": "​",
            "style": "IPY_MODEL_56513e73f1a840e99fa427ba115d4e79",
            "value": "model.safetensors: 100%"
          }
        },
        "53f3fc3f9a7a4472b3e8419ef54c14d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8eefac7393f40fd802e2a10e6e1115d",
            "max": 915152932,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97a2b7ef90ee451baa64319ee874bec1",
            "value": 915152932
          }
        },
        "3b8c5c80f70f421fbe4fa27e368fc328": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7614a1d0b174b2488c3e7086220af43",
            "placeholder": "​",
            "style": "IPY_MODEL_fc1ba01c5a834bd88f6419c6ca34abbe",
            "value": " 915M/915M [00:04&lt;00:00, 233MB/s]"
          }
        },
        "9491b9312268405393632ff4416848a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35e2c3b6414d4bc6b2e50d12b3b9ffc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56513e73f1a840e99fa427ba115d4e79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8eefac7393f40fd802e2a10e6e1115d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97a2b7ef90ee451baa64319ee874bec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7614a1d0b174b2488c3e7086220af43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc1ba01c5a834bd88f6419c6ca34abbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68eb3c4409974abab9a4fa73059c2165": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe8a0f8adaa54a719f4196d4dceee307",
              "IPY_MODEL_7fa076dd27b24e9bbe573bd3af7941a8",
              "IPY_MODEL_bcd809d8391146ff99fde1ebb08f3784"
            ],
            "layout": "IPY_MODEL_70f7a60981c542f4929e9a4545290141"
          }
        },
        "fe8a0f8adaa54a719f4196d4dceee307": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_191f6411312a4802ac33b2c611f79b5e",
            "placeholder": "​",
            "style": "IPY_MODEL_ca7424f96bc24b7486e39a05d8be0411",
            "value": "Predicting DataLoader 0: 100%"
          }
        },
        "7fa076dd27b24e9bbe573bd3af7941a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a32a2af75ffa41119fd25cf6caef4802",
            "max": 213,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a00a09355b647f1bb11be429fe02cea",
            "value": 213
          }
        },
        "bcd809d8391146ff99fde1ebb08f3784": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_659a2cf5ba5044348fbc13cacced501f",
            "placeholder": "​",
            "style": "IPY_MODEL_7d3a750e18ae484ca41712780256fb85",
            "value": " 213/213 [03:17&lt;00:00,  1.08it/s]"
          }
        },
        "70f7a60981c542f4929e9a4545290141": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "191f6411312a4802ac33b2c611f79b5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca7424f96bc24b7486e39a05d8be0411": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a32a2af75ffa41119fd25cf6caef4802": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a00a09355b647f1bb11be429fe02cea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "659a2cf5ba5044348fbc13cacced501f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d3a750e18ae484ca41712780256fb85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "dpvd55CLKTRf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bdb20c0-f8a8-497d-9469-cf63721dc384"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install pytorch-lightning"
      ],
      "metadata": {
        "id": "aYXJQq3ey3ix"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 임포트\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pytorch_lightning as pl\n",
        "from torchvision.transforms import v2\n",
        "import cv2\n",
        "from transformers import AutoImageProcessor, AutoModel\n",
        "from torch.utils.data import default_collate\n",
        "from argparse import ArgumentParser\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 설정\n",
        "parser = ArgumentParser(description=\"lowreso_imgclf\")\n",
        "parser.add_argument('--image_pretrained_model', default=\"beit-base-patch16-224-pt22k-ft22k\", type=str)\n",
        "parser.add_argument('--image_size', default=224, type=int)\n",
        "parser.add_argument('--aug_p', default=1, type=float)\n",
        "parser.add_argument('--optimizer', default=\"adamw\", type=str)\n",
        "parser.add_argument('--learning_rate', default=0.00003, type=float)\n",
        "parser.add_argument('--scheduler', default=\"cosine\", type=str)\n",
        "parser.add_argument('--batch_size', default=32, type=int)\n",
        "parser.add_argument('--epochs', default=1, type=int)\n",
        "parser.add_argument('--cv', default=5, type=int)\n",
        "parser.add_argument('--seed', default=826, type=int)\n",
        "parser.add_argument('--mixed_precision', default=16, type=int)\n",
        "parser.add_argument('--device', default=1, type=int)\n",
        "parser.add_argument('--num_workers', default=0, type=int)\n",
        "args = parser.parse_args('')\n",
        "\n",
        "# 시드 설정\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "def set_seeds(seed=args.seed):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    pl.seed_everything(seed)\n",
        "\n",
        "set_seeds()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOT3RY-BCKyt",
        "outputId": "9579febb-6591-4ab0-f33d-88f8215932ed"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 설정\n",
        "img_model_name = \"microsoft/beit-base-patch16-224-pt22k-ft22k\"\n",
        "latent_dim = 768\n",
        "processor = AutoImageProcessor.from_pretrained(img_model_name)\n",
        "\n",
        "# 데이터 로드\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Bird/data/data/train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Bird/data/data/test.csv')\n",
        "\n",
        "# 경로 설정\n",
        "train_df[\"img_path\"] = train_df[\"img_path\"].str.replace('./train/', '/content/drive/MyDrive/Colab Notebooks/Bird/data/data/train/')\n",
        "test_df[\"img_path\"] = test_df[\"img_path\"].str.replace('./test/', '/content/drive/MyDrive/Colab Notebooks/Bird/data/data/test/')\n",
        "train_df[\"upscale_img_path\"] = train_df[\"upscale_img_path\"].str.replace('./upscale_train/', '/content/drive/MyDrive/Colab Notebooks/Bird/data/data/upscale_train/')\n",
        "\n",
        "# 레이블 인코딩\n",
        "train_labels = train_df[\"label\"]\n",
        "label_unique = {k:v for k,v in zip(sorted(np.unique(train_labels)), range(len(np.unique(train_labels))))}\n",
        "train_df[\"label\"] = train_df[\"label\"].apply(lambda x : label_unique[x])\n",
        "\n",
        "# CutMix 초기화\n",
        "cutmix = v2.CutMix(num_classes=len(label_unique))"
      ],
      "metadata": {
        "id": "iiUv8NKKCL5D"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset 클래스\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, df, img_path, is_test=False, transform=None):\n",
        "        self.df = df\n",
        "        self.processor = processor\n",
        "        self.img_path = img_path\n",
        "        self.is_test = is_test\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        image = cv2.imread(row[self.img_path])\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if not self.is_test:\n",
        "            encoding = self.processor(images=image, return_tensors=\"pt\")\n",
        "            encoding[\"labels\"] = torch.tensor(row['label'], dtype=torch.long)\n",
        "            for k,v in encoding.items():\n",
        "                if hasattr(v, 'squeeze'):\n",
        "                    encoding[k] = v.squeeze()\n",
        "            return encoding\n",
        "\n",
        "        encoding = self.processor(images=image, return_tensors=\"pt\")\n",
        "        for k,v in encoding.items():\n",
        "            if hasattr(v, 'squeeze'):\n",
        "                encoding[k] = v.squeeze()\n",
        "        return encoding\n",
        "\n",
        "# 모델 클래스들\n",
        "class ImageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = AutoModel.from_pretrained(img_model_name)\n",
        "        self.clf = nn.Linear(latent_dim, len(label_unique))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        enc = self.model(inputs)\n",
        "        x = enc.pooler_output\n",
        "        outputs = self.clf(x)\n",
        "        return outputs\n",
        "\n",
        "class ImageClassifier(pl.LightningModule):\n",
        "    def __init__(self, backbone, args):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)\n",
        "\n",
        "    def step(self, batch):\n",
        "        x = batch[\"pixel_values\"]\n",
        "        y = batch[\"labels\"]\n",
        "        y_hat = self.forward(x)\n",
        "        loss = nn.CrossEntropyLoss()(y_hat, y)\n",
        "        return loss, y, y_hat\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss_ce, y, y_hat = self.step(batch)\n",
        "        loss_cos = nn.CosineEmbeddingLoss()(\n",
        "            y_hat, y, torch.Tensor([1]).to(self.device)\n",
        "        )\n",
        "        loss = loss_ce + loss_cos\n",
        "        print(f\"Batch {batch_idx}, Loss: {loss.item()}\")\n",
        "        f1 = f1_score(y_hat.max(dim=1)[1].cpu().numpy(), y.max(dim=1)[1].cpu().numpy(), average='macro')\n",
        "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        self.log(\"train_f1\", f1, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss_ce, y, y_hat = self.step(batch)\n",
        "        loss_cos = nn.CosineEmbeddingLoss()(\n",
        "            y_hat, F.one_hot(y.long(), len(label_unique)), torch.Tensor([1]).to(self.device)\n",
        "        )\n",
        "        loss = loss_ce + loss_cos\n",
        "        f1 = f1_score(y_hat.max(dim=1)[1].cpu().numpy(), y.cpu().numpy(), average='macro')\n",
        "        self.log('val_loss', loss, on_epoch=True, prog_bar=True)\n",
        "        self.log(\"val_f1\", f1, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.AdamW(self.parameters(), lr=args.learning_rate)\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "            optimizer=optimizer,\n",
        "            T_max=max(args.epochs//2, 1),\n",
        "            eta_min=args.learning_rate//10,\n",
        "        )\n",
        "        return [optimizer], [scheduler]\n",
        "\n",
        "def collate_fn(batch):\n",
        "    data = default_collate(batch)\n",
        "    data = cutmix(data['pixel_values'], data['labels'])\n",
        "    return {'pixel_values': data[0], 'labels': data[1]}"
      ],
      "metadata": {
        "id": "Lh2H9_cJCL7t"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 준비\n",
        "val_f1_list = []\n",
        "skf = StratifiedKFold(n_splits=args.cv, shuffle=True, random_state=args.seed)\n",
        "\n",
        "# 학습 수행\n",
        "for i, (train_index, val_index) in enumerate(skf.split(train_df, train_df[\"label\"])):\n",
        "    temp_df = train_df.iloc[train_index]\n",
        "    val_df = train_df.iloc[val_index]\n",
        "\n",
        "    # 데이터셋 생성\n",
        "    train_ds_low = ImageDataset(temp_df, \"img_path\", is_test=False)\n",
        "    train_ds_high = ImageDataset(temp_df, \"upscale_img_path\", is_test=False)\n",
        "    train_ds = train_ds_low + train_ds_high\n",
        "    val_ds = ImageDataset(val_df, \"img_path\", is_test=False)\n",
        "\n",
        "    # 데이터로더 설정\n",
        "    train_dataloader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True,\n",
        "                                  num_workers=args.num_workers, collate_fn=collate_fn)\n",
        "    val_dataloader = DataLoader(val_ds, batch_size=args.batch_size, shuffle=False,\n",
        "                                num_workers=args.num_workers)\n",
        "\n",
        "    # 모델 및 트레이너 설정\n",
        "    model = ImageClassifier(ImageModel(), args)\n",
        "    callbacks = [pl.callbacks.ModelCheckpoint(\n",
        "        dirpath=\"saved/\",\n",
        "        filename=f\"beit-base-patch16-224-pt22k-ft22k_{i}\",\n",
        "        monitor=\"val_f1\",\n",
        "        mode=\"max\"\n",
        "    )]\n",
        "\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=args.epochs,\n",
        "        accelerator=\"auto\",\n",
        "        callbacks=[*callbacks, pl.callbacks.TQDMProgressBar(refresh_rate=1)],\n",
        "        precision=args.mixed_precision,\n",
        "        devices=args.device\n",
        "    )\n",
        "\n",
        "    # 학습\n",
        "    trainer.fit(model, train_dataloader, val_dataloader)\n",
        "\n",
        "    # 체크포인트 로드\n",
        "    ckpt = torch.load(f\"saved/beit-base-patch16-224-pt22k-ft22k_{i}.ckpt\", map_location=device)\n",
        "    model.load_state_dict(ckpt['state_dict'])\n",
        "\n",
        "    # 검증 결과 저장\n",
        "    eval_dict = trainer.validate(model, dataloaders=val_dataloader)[0]\n",
        "    val_f1_list.append(eval_dict[\"val_f1\"])\n",
        "\n",
        "# 검증 F1 평균 출력\n",
        "val_f1_mean = np.mean(val_f1_list)\n",
        "print(f\"Validation F1 Mean: {val_f1_mean}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bd689b2a419749beb53266385cb74125",
            "512653525f4244799667304be48104e6",
            "fccfbedb6177454fbde89b74cdfef38e",
            "234e1cca4cbe422aa7a83e907c242cbe",
            "91ae20cb50e444f5bf4c208116f406f4",
            "2a16518160244ac5bf2030dca2c9b6ff",
            "5cfb3bff9f8e4974911e328d9d07d09d",
            "179f17a7573e4d9c8999a9066387b50b",
            "ea69c94d529044f29084fb1edee34cec",
            "c76db074928648e49f38792380d8a4ac",
            "a2fac5e3d6c24d27a4311ac367a62cd7",
            "c0c5ffb124f44a3aa9ad60232092c6c3",
            "8a3cd2f4f3434a0ab5dd97d232dbd8dd",
            "b0e7d78ec46646cbb6ac96b7bbfe7aba",
            "ad1c79a43fad40638ff2cd9f8429c34a",
            "a66484ab139a40cab28786cbdb368bc2",
            "0baf674906c34cfa8424ddf681742fce",
            "3f98060dcdbf4554aa575128144e3295",
            "4332e40256b34cd199a25f5c036c369e",
            "e50f93e01b7248f4bb96d579c4a1a321",
            "96722a63eb2c44ae92767385bd16e3dc",
            "6c0c787ed9514ca2ad7cce06198c7ad5"
          ]
        },
        "id": "k7F9_tvnCL-S",
        "outputId": "313dd6a4-27ac-4db7-b724-65a6f16f902f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name     | Type       | Params | Mode \n",
            "------------------------------------------------\n",
            "0 | backbone | ImageModel | 85.8 M | train\n",
            "------------------------------------------------\n",
            "85.8 M    Trainable params\n",
            "0         Non-trainable params\n",
            "85.8 M    Total params\n",
            "343.125   Total estimated model params size (MB)\n",
            "2         Modules in train mode\n",
            "250       Modules in eval mode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd689b2a419749beb53266385cb74125"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0c5ffb124f44a3aa9ad60232092c6c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0, Loss: 4.329592704772949\n",
            "Batch 1, Loss: 4.052292346954346\n",
            "Batch 2, Loss: 4.203272819519043\n",
            "Batch 3, Loss: 4.138926982879639\n",
            "Batch 4, Loss: 4.01518440246582\n",
            "Batch 5, Loss: 4.089448928833008\n",
            "Batch 6, Loss: 4.047309875488281\n",
            "Batch 7, Loss: 4.097050189971924\n",
            "Batch 8, Loss: 4.069786071777344\n",
            "Batch 9, Loss: 4.300349235534668\n",
            "Batch 10, Loss: 3.748945951461792\n",
            "Batch 11, Loss: 3.5598936080932617\n",
            "Batch 12, Loss: 4.0409722328186035\n",
            "Batch 13, Loss: 3.755070209503174\n",
            "Batch 14, Loss: 3.78810977935791\n",
            "Batch 15, Loss: 3.748483180999756\n",
            "Batch 16, Loss: 3.713646650314331\n",
            "Batch 17, Loss: 3.6703433990478516\n",
            "Batch 18, Loss: 3.395648241043091\n",
            "Batch 19, Loss: 3.6953468322753906\n",
            "Batch 20, Loss: 3.6006968021392822\n",
            "Batch 21, Loss: 3.7484707832336426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:\n",
            "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'exit' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    573\u001b[0m         )\n\u001b[0;32m--> 574\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1024\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mdataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m             \u001b[0;31m# TODO: we should instead use the batch_idx returned by the fetcher, however, that will require saving the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fetchers.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# this will run only when no pre-fetching was done.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fetchers.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/combined_loader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Sequential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/combined_loader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-06fa21e86682>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-66e7fcaa1941>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# 체크포인트 로드\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainerStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRUNNING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    539\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_SubprocessScriptLauncher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_sigkill_signal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BeitFeatureExtractor, BeitForImageClassification\n",
        "from PIL import Image\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, df, img_path_col, is_test=False):\n",
        "        self.df = df\n",
        "        self.img_path_col = img_path_col\n",
        "        self.is_test = is_test\n",
        "        self.feature_extractor = BeitFeatureExtractor.from_pretrained('microsoft/beit-base-patch16-224-pt22k-ft22k')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.df.iloc[idx][self.img_path_col]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # Apply feature extraction\n",
        "        features = self.feature_extractor(images=image, return_tensors=\"pt\")\n",
        "        pixel_values = features['pixel_values'].squeeze()\n",
        "\n",
        "        if self.is_test:\n",
        "            return pixel_values\n",
        "        else:\n",
        "            label = self.df.iloc[idx]['label']\n",
        "            return pixel_values, label\n",
        "\n",
        "class ImageClassifier(pl.LightningModule):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.model = BeitForImageClassification.from_pretrained(\n",
        "            'microsoft/beit-base-patch16-224-pt22k-ft22k',\n",
        "            num_labels=num_classes,\n",
        "            ignore_mismatched_sizes=True\n",
        "        )\n",
        "\n",
        "    def forward(self, pixel_values):\n",
        "        outputs = self.model(pixel_values=pixel_values)\n",
        "        return outputs.logits\n",
        "\n",
        "    def predict_step(self, batch, batch_idx):\n",
        "        pixel_values = batch\n",
        "        logits = self(pixel_values)\n",
        "        return torch.softmax(logits, dim=1)\n",
        "\n",
        "def predict_images(test_df, args, label_unique, device):\n",
        "    preds_list = []\n",
        "\n",
        "    # 테스트 데이터셋 생성\n",
        "    test_ds = ImageDataset(test_df, \"img_path\", is_test=True)\n",
        "    test_dataloader = DataLoader(\n",
        "        test_ds,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=args.num_workers\n",
        "    )\n",
        "\n",
        "    # Cross validation 예측 수행\n",
        "    for i in range(args.cv):\n",
        "        # 모델 생성 및 체크포인트 로드\n",
        "        model = ImageClassifier(num_classes=len(label_unique))\n",
        "        ckpt = torch.load(\n",
        "            f\"saved/beit-base-patch16-224-pt22k-ft22k_{i}.ckpt\",\n",
        "            map_location=device\n",
        "        )\n",
        "        model.load_state_dict(ckpt['state_dict'])\n",
        "        model = model.to(device)\n",
        "        model.eval()\n",
        "\n",
        "        # 예측\n",
        "        trainer = pl.Trainer(\n",
        "            accelerator=\"auto\",\n",
        "            precision=args.mixed_precision,\n",
        "            devices=args.device\n",
        "        )\n",
        "        y_preds = trainer.predict(model, dataloaders=test_dataloader)\n",
        "        preds_list.append(np.vstack(y_preds))\n",
        "\n",
        "    # 예측 결과 집계\n",
        "    y_pred = np.mean(preds_list, axis=0)\n",
        "    preds = y_pred.argmax(axis=1)\n",
        "\n",
        "    # 레이블 디코딩 및 결과 저장\n",
        "    label_decoder = {val: key for key, val in label_unique.items()}\n",
        "    result = [label_decoder[pred] for pred in preds]\n",
        "\n",
        "    submit = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Bird/data/data/sample_submission.csv')\n",
        "    submit[\"label\"] = result\n",
        "    submit.to_csv('beit-base-patch16-224-pt22k-ft22k.csv', index=False)\n",
        "\n",
        "    return submit"
      ],
      "metadata": {
        "id": "4Mfz9j14JJfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과출력"
      ],
      "metadata": {
        "id": "Fh9Y-rMo1pDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoModel, AutoProcessor\n",
        "from sklearn.metrics import f1_score\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.dataloader import default_collate\n",
        "\n",
        "# 데이터 로드\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Bird/data/data/train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Bird/data/data/test.csv')\n",
        "test_df[\"img_path\"] = test_df[\"img_path\"].apply(lambda x: os.path.join('/content/drive/MyDrive/Colab Notebooks/Bird/data/data/test', x))\n",
        "\n",
        "\n",
        "# 레이블 인코딩\n",
        "train_labels = train_df[\"label\"]\n",
        "label_unique = {k:v for k,v in zip(sorted(np.unique(train_labels)), range(len(np.unique(train_labels))))}\n",
        "\n",
        "# 모델 설정\n",
        "img_model_name = \"microsoft/swinv2-large-patch4-window12-192-22k\"\n",
        "latent_dim = 1536\n",
        "processor = AutoProcessor.from_pretrained(img_model_name)\n",
        "\n",
        "# Dataset 클래스\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, df, img_path, is_test=False, transform=None):\n",
        "        self.df = df\n",
        "        self.processor = processor\n",
        "        self.img_path = img_path\n",
        "        self.is_test = is_test\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        image = cv2.imread(row[self.img_path])\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if not self.is_test:\n",
        "            encoding = self.processor(images=image, return_tensors=\"pt\")\n",
        "            encoding[\"labels\"] = torch.tensor(row['label'], dtype=torch.long)\n",
        "            for k,v in encoding.items():\n",
        "                if hasattr(v, 'squeeze'):\n",
        "                    encoding[k] = v.squeeze()\n",
        "            return encoding\n",
        "\n",
        "        encoding = self.processor(images=image, return_tensors=\"pt\")\n",
        "        for k,v in encoding.items():\n",
        "            if hasattr(v, 'squeeze'):\n",
        "                encoding[k] = v.squeeze()\n",
        "        return encoding\n",
        "\n",
        "# 모델 클래스들\n",
        "class ImageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = AutoModel.from_pretrained(img_model_name)\n",
        "        # 인덱스를 1로 설정\n",
        "        self.clf = nn.Sequential(\n",
        "            nn.Identity(),  # 0번 인덱스\n",
        "            nn.Linear(latent_dim, len(label_unique))  # 1번 인덱스\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        enc = self.model(inputs)\n",
        "        x = enc.pooler_output\n",
        "        outputs = self.clf(x)\n",
        "        return outputs\n",
        "\n",
        "class ImageClassifier(pl.LightningModule):\n",
        "    def __init__(self, backbone, args):\n",
        "        super().__init__()\n",
        "        self.model = backbone\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def predict_step(self, batch, batch_idx):\n",
        "        x = batch[\"pixel_values\"]\n",
        "        y_hat = self.forward(x)\n",
        "        return torch.softmax(y_hat, dim=1)\n",
        "# 매개변수 설정\n",
        "class Args:\n",
        "    batch_size = 32\n",
        "    num_workers = 4\n",
        "    cv = 1\n",
        "    mixed_precision = '16-mixed'\n",
        "    device = 1\n",
        "    learning_rate = 1e-5\n",
        "    epochs = 10\n",
        "\n",
        "args = Args()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def predict_images(test_df, args, label_unique, device):\n",
        "    preds_list = []\n",
        "\n",
        "    # 테스트 데이터셋 생성\n",
        "    test_ds = ImageDataset(test_df, \"img_path\", is_test=True)\n",
        "    test_dataloader = DataLoader(\n",
        "        test_ds,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=args.num_workers\n",
        "    )\n",
        "\n",
        "    # 체크포인트 파일 경로\n",
        "    checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/Bird/data/checkpoints/swinv2-large-resize-fold_idx=0-epoch=00-train_loss=0.5881-val_score=0.9584.ckpt'\n",
        "\n",
        "    # 모델 생성 및 체크포인트 로드\n",
        "    model = ImageClassifier(ImageModel(), args)\n",
        "    ckpt = torch.load(checkpoint_path, map_location=device)\n",
        "    model.load_state_dict(ckpt['state_dict'])\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # 예측\n",
        "    trainer = pl.Trainer(\n",
        "        accelerator=\"auto\",\n",
        "        precision=args.mixed_precision,\n",
        "        devices=args.device\n",
        "    )\n",
        "    y_preds = trainer.predict(model, dataloaders=test_dataloader)\n",
        "    preds_list.append(np.vstack(y_preds))\n",
        "\n",
        "    # 예측 결과 집계\n",
        "    y_pred = np.mean(preds_list, axis=0)\n",
        "    preds = y_pred.argmax(axis=1)\n",
        "\n",
        "    # 레이블 디코딩 및 결과 저장\n",
        "    label_decoder = {val: key for key, val in label_unique.items()}\n",
        "    result = [label_decoder[pred] for pred in preds]\n",
        "\n",
        "    submit = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Bird/data/data/sample_submission.csv')\n",
        "    submit[\"label\"] = result\n",
        "    submit.to_csv('swinv2_predictions.csv', index=False)\n",
        "\n",
        "    return submit\n",
        "\n",
        "# 예측 실행\n",
        "results = predict_images(test_df, args, label_unique, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736,
          "referenced_widgets": [
            "2592f34d027d46218a6563a381fe6f29",
            "bd3dd174cca34b1faba5ed8544626386",
            "ec0bb50b94f643b9828fc140a284ba35",
            "34333efbab8347f9bfc9dc42dd8c593e",
            "3a2c5717eeaf41eeac4d2a1ead92f47e",
            "f6fcedb25e8a4df3b7cc3c3609651559",
            "d3502610024a4f2bb134664946bfde08",
            "29c05e8784ea45919321ff3286e37df4",
            "917fbcbb5e5e4d1ca250448f3a0d0d39",
            "56321910255d4eab96176542cd7db2d4",
            "8ace51d4a416454dae652940f309c111"
          ]
        },
        "id": "6I50GqLIzkgu",
        "outputId": "8b66bea5-5afc-4c92-f002-c0d9bcce55c3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predicting: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2592f34d027d46218a6563a381fe6f29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "Caught error in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-34-c8ea2dc7ece5>\", line 43, in __getitem__\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\ncv2.error: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-c8ea2dc7ece5>\u001b[0m in \u001b[0;36m<cell line: 147>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;31m# 예측 실행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-c8ea2dc7ece5>\u001b[0m in \u001b[0;36mpredict_images\u001b[0;34m(test_df, args, label_unique, device)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mdevices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     )\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0mpreds_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainerStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRUNNING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m         return call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    859\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_predict_impl\u001b[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_provided\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_provided\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m         )\n\u001b[0;32m--> 897\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;31m# RUN THE TRAINER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0misolate_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/utilities.py\u001b[0m in \u001b[0;36m_decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mcontext_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcontext_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mloop_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_decorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/prediction_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0mdataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                     \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_progress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_last_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;31m# run step hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fetchers.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# this will run only when no pre-fetching was done.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;31m# the iterator is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fetchers.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_profiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/combined_loader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_ITERATOR_RETURN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Sequential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/combined_loader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;31m# try the next iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1463\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1465\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1489\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1491\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1492\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    713\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: Caught error in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-34-c8ea2dc7ece5>\", line 43, in __getitem__\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\ncv2.error: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoModel, AutoProcessor\n",
        "\n",
        "# 모델 설정\n",
        "img_model_name = \"microsoft/swinv2-large-patch4-window12-192-22k\"\n",
        "latent_dim = 1536\n",
        "processor = AutoProcessor.from_pretrained(img_model_name)\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, df, img_path, is_test=False, transform=None):\n",
        "        self.df = df\n",
        "        self.processor = processor\n",
        "        self.img_path = img_path\n",
        "        self.is_test = is_test\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            row = self.df.iloc[idx]\n",
        "            img_path = row[self.img_path]\n",
        "\n",
        "            if not os.path.exists(img_path):\n",
        "                print(f\"Image file not found: {img_path}\")\n",
        "                raise FileNotFoundError(f\"Image file not found: {img_path}\")\n",
        "\n",
        "            image = cv2.imread(img_path)\n",
        "            if image is None:\n",
        "                print(f\"Failed to load image: {img_path}\")\n",
        "                raise ValueError(f\"Failed to load image: {img_path}\")\n",
        "\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            if not self.is_test:\n",
        "                encoding = self.processor(images=image, return_tensors=\"pt\")\n",
        "                encoding[\"labels\"] = torch.tensor(row['label'], dtype=torch.long)\n",
        "                for k,v in encoding.items():\n",
        "                    if hasattr(v, 'squeeze'):\n",
        "                        encoding[k] = v.squeeze()\n",
        "                return encoding\n",
        "\n",
        "            encoding = self.processor(images=image, return_tensors=\"pt\")\n",
        "            for k,v in encoding.items():\n",
        "                if hasattr(v, 'squeeze'):\n",
        "                    encoding[k] = v.squeeze()\n",
        "            return encoding\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image at index {idx}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "class ImageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = AutoModel.from_pretrained(img_model_name)\n",
        "        self.clf = nn.Sequential(\n",
        "            nn.Identity(),  # 0번 인덱스\n",
        "            nn.Linear(latent_dim, len(label_unique))  # 1번 인덱스\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        enc = self.model(inputs)\n",
        "        x = enc.pooler_output\n",
        "        outputs = self.clf(x)\n",
        "        return outputs\n",
        "\n",
        "class ImageClassifier(pl.LightningModule):\n",
        "    def __init__(self, backbone, args):\n",
        "        super().__init__()\n",
        "        self.model = backbone\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def predict_step(self, batch, batch_idx):\n",
        "        x = batch[\"pixel_values\"]\n",
        "        y_hat = self.forward(x)\n",
        "        return torch.softmax(y_hat, dim=1)\n",
        "\n",
        "def predict_images(test_df, args, label_unique, device):\n",
        "    preds_list = []\n",
        "\n",
        "    # 테스트 데이터셋 생성\n",
        "    test_ds = ImageDataset(test_df, \"img_path\", is_test=True)\n",
        "    test_dataloader = DataLoader(\n",
        "        test_ds,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=args.num_workers\n",
        "    )\n",
        "\n",
        "    # 체크포인트 파일 경로\n",
        "    checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/Bird/data/checkpoints/swinv2-large-resize-fold_idx=0-epoch=00-train_loss=0.5881-val_score=0.9584.ckpt'\n",
        "\n",
        "    # 모델 생성 및 체크포인트 로드\n",
        "    model = ImageClassifier(ImageModel(), args)\n",
        "    ckpt = torch.load(checkpoint_path, map_location=device)\n",
        "    model.load_state_dict(ckpt['state_dict'])\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # 예측\n",
        "    trainer = pl.Trainer(\n",
        "        accelerator=\"auto\",\n",
        "        precision=args.mixed_precision,\n",
        "        devices=args.device\n",
        "    )\n",
        "    y_preds = trainer.predict(model, dataloaders=test_dataloader)\n",
        "    preds_list.append(np.vstack(y_preds))\n",
        "\n",
        "    # 예측 결과 집계\n",
        "    y_pred = np.mean(preds_list, axis=0)\n",
        "    preds = y_pred.argmax(axis=1)\n",
        "\n",
        "    # 레이블 디코딩 및 결과 저장\n",
        "    label_decoder = {val: key for key, val in label_unique.items()}\n",
        "    result = [label_decoder[pred] for pred in preds]\n",
        "\n",
        "    submit = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Bird/data/data/sample_submission.csv')\n",
        "    submit[\"label\"] = result\n",
        "    submit.to_csv('swinv2_predictions.csv', index=False)\n",
        "\n",
        "    return submit\n",
        "\n",
        "# 테스트 데이터프레임 로드\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Bird/data/data/test.csv')\n",
        "\n",
        "# 이미지 경로 수정 (./test/ 부분을 제거하고 직접 경로 설정)\n",
        "test_df[\"img_path\"] = test_df[\"img_path\"].apply(lambda x: os.path.join('/content/drive/MyDrive/Colab Notebooks/Bird/data/data/test', os.path.basename(x)))\n",
        "\n",
        "# 첫 번째 이미지 경로 확인\n",
        "print(\"First image path:\", test_df[\"img_path\"].iloc[0])\n",
        "print(\"File exists:\", os.path.exists(test_df[\"img_path\"].iloc[0]))\n",
        "# Args 설정\n",
        "class Args:\n",
        "    batch_size = 32\n",
        "    num_workers = 4\n",
        "    cv = 1\n",
        "    mixed_precision = '16-mixed'\n",
        "    device = 1\n",
        "    learning_rate = 1e-5\n",
        "    epochs = 10\n",
        "\n",
        "args = Args()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 예측 실행\n",
        "results = predict_images(test_df, args, label_unique, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230,
          "referenced_widgets": [
            "2cced864c51f48a7a0268cd83db9710b",
            "7387fbd601d34ad1aa36b098c195dbc1",
            "53f3fc3f9a7a4472b3e8419ef54c14d9",
            "3b8c5c80f70f421fbe4fa27e368fc328",
            "9491b9312268405393632ff4416848a4",
            "35e2c3b6414d4bc6b2e50d12b3b9ffc7",
            "56513e73f1a840e99fa427ba115d4e79",
            "c8eefac7393f40fd802e2a10e6e1115d",
            "97a2b7ef90ee451baa64319ee874bec1",
            "c7614a1d0b174b2488c3e7086220af43",
            "fc1ba01c5a834bd88f6419c6ca34abbe",
            "68eb3c4409974abab9a4fa73059c2165",
            "fe8a0f8adaa54a719f4196d4dceee307",
            "7fa076dd27b24e9bbe573bd3af7941a8",
            "bcd809d8391146ff99fde1ebb08f3784",
            "70f7a60981c542f4929e9a4545290141",
            "191f6411312a4802ac33b2c611f79b5e",
            "ca7424f96bc24b7486e39a05d8be0411",
            "a32a2af75ffa41119fd25cf6caef4802",
            "1a00a09355b647f1bb11be429fe02cea",
            "659a2cf5ba5044348fbc13cacced501f",
            "7d3a750e18ae484ca41712780256fb85"
          ]
        },
        "id": "HojX28Bh2pJF",
        "outputId": "b0e40a38-70b5-4cea-edd4-35e4c589952c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First image path: /content/drive/MyDrive/Colab Notebooks/Bird/data/data/test/TEST_00000.jpg\n",
            "File exists: True\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/915M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2cced864c51f48a7a0268cd83db9710b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predicting: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68eb3c4409974abab9a4fa73059c2165"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# print(\"현재 작업 디렉토리:\", os.getcwd())"
      ],
      "metadata": {
        "id": "4QK2wJQVCMAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8fd851c-d3d8-43a3-fb15-6626fec04850"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 작업 디렉토리: /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dAnhylUPCMDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSL1Su0ufePd"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # Imports\n",
        "# import os\n",
        "# import random\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from sklearn.model_selection import StratifiedKFold\n",
        "# from sklearn.metrics import f1_score\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# from torch.nn import functional as F\n",
        "# from torch.utils.data import Dataset, DataLoader\n",
        "# import pytorch_lightning as pl\n",
        "# from torchvision.transforms import v2\n",
        "# import cv2\n",
        "# from transformers import AutoImageProcessor, AutoModel\n",
        "# from torch.utils.data import default_collate\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "# # Config\n",
        "# parser = ArgumentParser(description=\"lowreso_imgclf\")\n",
        "# parser.add_argument('--image_pretrained_model', default=\"beit-base-patch16-224-pt22k-ft22k\", type=str)\n",
        "# parser.add_argument('--image_size', default=224, type=int)\n",
        "# parser.add_argument('--aug_p', default=1, type=float)\n",
        "# parser.add_argument('--optimizer', default=\"adamw\", type=str)\n",
        "# parser.add_argument('--learning_rate', default=0.00003, type=float)\n",
        "# parser.add_argument('--scheduler', default=\"cosine\", type=str)\n",
        "# parser.add_argument('--batch_size', default=64, type=int)\n",
        "# parser.add_argument('--epochs', default=1, type=int)  # Changed to 1\n",
        "# parser.add_argument('--cv', default=5, type=int)\n",
        "# parser.add_argument('--seed', default=826, type=int)\n",
        "# parser.add_argument('--mixed_precision', default=16, type=int)\n",
        "# parser.add_argument('--device', default=1, type=int)  # Changed to single GPU\n",
        "# parser.add_argument('--num_workers', default=0, type=int)\n",
        "# args = parser.parse_args('')\n",
        "\n",
        "# # Set device and seed\n",
        "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# def set_seeds(seed=args.seed):\n",
        "#     np.random.seed(seed)\n",
        "#     random.seed(seed)\n",
        "#     torch.manual_seed(seed)\n",
        "#     torch.cuda.manual_seed(seed)\n",
        "#     torch.backends.cudnn.deterministic = True\n",
        "#     torch.backends.cudnn.benchmark = False\n",
        "#     pl.seed_everything(seed)\n",
        "\n",
        "# set_seeds()\n",
        "\n",
        "# # Model config\n",
        "# img_model_name = \"microsoft/beit-base-patch16-224-pt22k-ft22k\"\n",
        "# latent_dim = 768\n",
        "# processor = AutoImageProcessor.from_pretrained(img_model_name)\n",
        "\n",
        "# # Load and preprocess data\n",
        "# train_df[\"img_path\"] = train_df[\"img_path\"].str.replace('./train/', '/content/drive/MyDrive/Colab Notebooks/Bird/data/data/train/')\n",
        "# test_df[\"img_path\"] = test_df[\"img_path\"].str.replace('./test/', '/content/drive/MyDrive/Colab Notebooks/Bird/data/data/test/')\n",
        "# train_df[\"upscale_img_path\"] = train_df[\"upscale_img_path\"].str.replace('./upscale_train/', '/content/drive/MyDrive/Colab Notebooks/Bird/data/data/upscale_train/')\n",
        "\n",
        "# # 학습 데이터셋 구성 부분도 원래대로 복구\n",
        "# train_ds_low = ImageDataset(temp_df, \"img_path\", is_test=False)\n",
        "# train_ds_high = ImageDataset(temp_df, \"upscale_img_path\", is_test=False)\n",
        "# train_ds = train_ds_low + train_ds_high\n",
        "\n",
        "# # Create label mapping\n",
        "# train_labels = train_df[\"label\"]\n",
        "# label_unique = {k:v for k,v in zip(sorted(np.unique(train_labels)), range(len(np.unique(train_labels))))}\n",
        "# train_df[\"label\"] = train_df[\"label\"].apply(lambda x : label_unique[x])\n",
        "\n",
        "# # Initialize CutMix\n",
        "# cutmix = v2.CutMix(num_classes=len(label_unique))\n",
        "\n",
        "# # Dataset class\n",
        "# class ImageDataset(Dataset):\n",
        "#     def __init__(self, df, img_path, is_test=False, transform=None):\n",
        "#         self.df = df\n",
        "#         self.processor = processor\n",
        "#         self.img_path = img_path\n",
        "#         self.is_test = is_test\n",
        "#         self.transform = transform\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.df)\n",
        "#     def __getitem__(self, idx):\n",
        "#         row = self.df.iloc[idx]\n",
        "#         image = cv2.imread(row[self.img_path])\n",
        "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "#         encoding = self.processor(images=image, return_tensors=\"pt\")\n",
        "#         pixel_values = encoding[\"pixel_values\"]\n",
        "#         print(f\"Pixel values shape in Dataset: {pixel_values.shape}\")  # 디버깅 출력\n",
        "\n",
        "#         if not self.is_test:\n",
        "#             encoding[\"labels\"] = torch.tensor(row['label'], dtype=torch.long)\n",
        "#         return encoding\n",
        "\n",
        "\n",
        "\n",
        "# # Model classes\n",
        "# class ImageModel(nn.Module):\n",
        "#     def forward(self, inputs):\n",
        "#         print(f\"Model input shape: {inputs.shape}\")  # 디버깅 출력\n",
        "\n",
        "#         # 입력 차원 강제 조정\n",
        "#         if len(inputs.shape) != 4:\n",
        "#             inputs = inputs.squeeze(1)  # 필요시 수정\n",
        "#             print(f\"Adjusted input shape: {inputs.shape}\")\n",
        "\n",
        "#         enc = self.model(inputs)\n",
        "#         x = enc.pooler_output\n",
        "#         outputs = self.clf(x)\n",
        "#         return outputs\n",
        "\n",
        "\n",
        "# class ImageClassifier(pl.LightningModule):\n",
        "#     def __init__(self, backbone, args):\n",
        "#         super().__init__()\n",
        "#         self.backbone = backbone\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         return self.backbone(x)\n",
        "\n",
        "#     def step(self, batch):\n",
        "#         x = batch[\"pixel_values\"]\n",
        "#         y = batch[\"labels\"]\n",
        "#         y_hat = self.forward(x)\n",
        "#         loss = nn.CrossEntropyLoss()(y_hat, y)\n",
        "#         return loss, y, y_hat\n",
        "\n",
        "#     def training_step(self, batch, batch_idx):\n",
        "#         loss_ce, y, y_hat = self.step(batch)\n",
        "#         loss_cos = nn.CosineEmbeddingLoss()(\n",
        "#             y_hat, y, torch.Tensor([1]).to(self.device)\n",
        "#         )\n",
        "#         loss = loss_ce + loss_cos\n",
        "#         print(f\"Batch {batch_idx}, Loss: {loss.item()}\")\n",
        "#         f1 = f1_score(y_hat.max(dim=1)[1].cpu().numpy(), y.max(dim=1)[1].cpu().numpy(), average='macro')\n",
        "#         self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "#         self.log(\"train_f1\", f1, on_step=False, on_epoch=True, prog_bar=True)\n",
        "#         return loss\n",
        "\n",
        "#     def validation_step(self, batch, batch_idx):\n",
        "#         loss_ce, y, y_hat = self.step(batch)\n",
        "#         loss_cos = nn.CosineEmbeddingLoss()(\n",
        "#             y_hat, F.one_hot(y.long(), len(label_unique)), torch.Tensor([1]).to(self.device)\n",
        "#         )\n",
        "#         loss = loss_ce + loss_cos\n",
        "#         f1 = f1_score(y_hat.max(dim=1)[1].cpu().numpy(), y.cpu().numpy(), average='macro')\n",
        "#         self.log('val_loss', loss, on_epoch=True, prog_bar=True)\n",
        "#         self.log(\"val_f1\", f1, on_epoch=True, prog_bar=True)\n",
        "#         return loss\n",
        "#     def configure_optimizers(self):\n",
        "\n",
        "#       optimizer = torch.optim.AdamW(self.parameters(), lr=args.learning_rate)\n",
        "#       scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "#           optimizer=optimizer,\n",
        "#           T_max=max(args.epochs//2, 1),  # 최소값 1 설정\n",
        "#           eta_min=args.learning_rate//10,\n",
        "#       )\n",
        "#       return [optimizer], [scheduler]\n",
        "\n",
        "# # Collate function\n",
        "# def collate_fn(batch):\n",
        "#     data = default_collate(batch)\n",
        "#     print(f\"Before CutMix: {data['pixel_values'].shape}\")  # 디버깅 출력\n",
        "#     data = cutmix(data['pixel_values'], data['labels'])\n",
        "\n",
        "#     # 배치 차원 강제 보장\n",
        "#     if len(data[0].shape) != 4:\n",
        "#         data = (data[0].squeeze(1), data[1])  # 필요시 차원 조정\n",
        "\n",
        "#     print(f\"After CutMix: {data[0].shape}\")  # 디버깅 출력\n",
        "#     return {'pixel_values': data[0], 'labels': data[1]}\n",
        "\n",
        "# # Training\n",
        "# val_f1_list = []\n",
        "# preds_list = []\n",
        "\n",
        "# skf = StratifiedKFold(n_splits=args.cv, shuffle=True, random_state=args.seed)\n",
        "# print(torch.cuda.memory_summary())\n",
        "# for i, (train_index, val_index) in enumerate(skf.split(train_df, train_df[\"label\"])):\n",
        "#     temp_df = train_df.iloc[train_index]\n",
        "#     val_df = train_df.iloc[val_index]\n",
        "\n",
        "#     train_ds = ImageDataset(temp_df, \"img_path\", is_test=False)\n",
        "#     val_ds = ImageDataset(val_df, \"img_path\", is_test=False)\n",
        "#     test_ds = ImageDataset(test_df, \"img_path\", is_test=True)\n",
        "\n",
        "#     train_dataloader = DataLoader(\n",
        "#         train_ds, batch_size=args.batch_size, shuffle=True,\n",
        "#         num_workers=args.num_workers, collate_fn=collate_fn\n",
        "#     )\n",
        "#     val_dataloader = DataLoader(\n",
        "#         val_ds, batch_size=args.batch_size, shuffle=False,\n",
        "#         num_workers=args.num_workers\n",
        "#     )\n",
        "#     test_dataloader = DataLoader(\n",
        "#         test_ds, batch_size=args.batch_size, shuffle=False,\n",
        "#         num_workers=args.num_workers\n",
        "#     )\n",
        "\n",
        "#     # 디버깅 코드: 테스트 데이터 로더에서 배치 데이터 확인\n",
        "#     for batch in test_dataloader:\n",
        "#         print(f\"Test batch pixel_values shape: {batch['pixel_values'].shape}\")\n",
        "#         break\n",
        "\n",
        "\n",
        "#     model = ImageClassifier(ImageModel(), args)\n",
        "#     callbacks = [pl.callbacks.ModelCheckpoint(\n",
        "#         dirpath=\"saved/\",\n",
        "#         filename=f\"beit-base-patch16-224-pt22k-ft22k_{i}\",\n",
        "#         monitor=\"val_f1\",\n",
        "#         mode=\"max\"\n",
        "#     )]\n",
        "\n",
        "#     trainer = pl.Trainer(\n",
        "#         max_epochs=args.epochs,\n",
        "#         accelerator=\"auto\",\n",
        "#         callbacks=[*callbacks, pl.callbacks.TQDMProgressBar(refresh_rate=1)],\n",
        "#         precision=args.mixed_precision,\n",
        "#         devices=args.device\n",
        "#     )\n",
        "\n",
        "#     trainer.fit(model, train_dataloader, val_dataloader)\n",
        "\n",
        "#     # Load best checkpoint and make predictions\n",
        "#     ckpt = torch.load(f\"saved/beit-base-patch16-224-pt22k-ft22k_{i}.ckpt\", map_location=device)\n",
        "#     model.load_state_dict(ckpt['state_dict'])\n",
        "\n",
        "#     eval_dict = trainer.validate(model, dataloaders=val_dataloader)[0]\n",
        "#     val_f1_list.append(eval_dict[\"val_f1\"])\n",
        "\n",
        "#     # Trainer predict 호출\n",
        "#     y_preds = trainer.predict(model, dataloaders=test_dataloader)\n",
        "#     preds_list.append(np.vstack(y_preds))\n",
        "\n",
        "# # Final predictions and submission\n",
        "# val_f1_mean = np.mean(val_f1_list)\n",
        "# print(f\"Validation F1 Mean: {val_f1_mean}\")\n",
        "\n",
        "# y_pred = np.mean(preds_list, axis=0)\n",
        "# preds = y_pred.argmax(axis=1)\n",
        "\n",
        "# label_decoder = {val:key for key, val in label_unique.items()}\n",
        "# result = [label_decoder[pred] for pred in preds]\n",
        "\n",
        "# submit = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Bird/data/data/sample_submission.csv')\n",
        "# submit[\"label\"] = result\n",
        "# submit.to_csv('beit-base-patch16-224-pt22k-ft22k.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = ImageClassifier(ImageModel(), args)\n",
        "# print(f\"Number of model parameters: {sum(p.numel() for p in model.parameters())}\")\n"
      ],
      "metadata": {
        "id": "e-tEt6f0H28M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9bmSwLUzH50G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def collate_fn(batch):\n",
        "#     data = default_collate(batch)\n",
        "#     print(f\"Before CutMix: {data['pixel_values'].shape}\")\n",
        "#     data = cutmix(data['pixel_values'], data['labels'])\n",
        "#     print(f\"After CutMix: {data[0].shape}\")\n",
        "#     return {'pixel_values': data[0], 'labels': data[1]}\n"
      ],
      "metadata": {
        "id": "uYl3wIO1EZuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 기본 경로 수정\n",
        "# BASE_PATH = \"/content/drive/MyDrive/Colab Notebooks/Bird/data/data\"\n",
        "\n",
        "# # 이미지 경로 수정\n",
        "# train_df[\"img_path\"] = train_df[\"img_path\"].apply(lambda x : os.path.join(BASE_PATH, x))\n",
        "# test_df[\"img_path\"] = test_df[\"img_path\"].apply(lambda x : os.path.join(BASE_PATH, x))\n",
        "# train_df[\"upscale_img_path\"] = train_df[\"upscale_img_path\"].apply(lambda x : os.path.join(BASE_PATH, x))\n",
        "\n",
        "# # 경로 확인\n",
        "# print(train_df[\"img_path\"].iloc[0])\n",
        "# print(f\"File exists: {os.path.exists(train_df['img_path'].iloc[0])}\")"
      ],
      "metadata": {
        "id": "M-jtJf7Wg4hF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"Training image path example:\", train_df['img_path'].iloc[0])\n",
        "# print(\"Does file exist?\", os.path.exists(train_df['img_path'].iloc[0]))\n",
        "# print(\"Dataset size:\", len(train_df))"
      ],
      "metadata": {
        "id": "XgIpigrfhdLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load CSVs\n",
        "# train_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Bird/data/data/train.csv')\n",
        "# test_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Bird/data/data/test.csv')\n",
        "\n",
        "# # Set correct paths\n",
        "# train_df[\"img_path\"] = train_df[\"img_path\"].str.replace('./train/', '/content/drive/MyDrive/Colab Notebooks/Bird/data/data/train/')\n",
        "# test_df[\"img_path\"] = test_df[\"img_path\"].str.replace('./test/', '/content/drive/MyDrive/Colab Notebooks/Bird/data/data/test/')\n",
        "# train_df[\"upscale_img_path\"] = train_df[\"upscale_img_path\"].str.replace('./train/', '/content/drive/MyDrive/Colab Notebooks/Bird/data/data/train/')\n",
        "\n",
        "# # Verify\n",
        "# print(\"Sample train path:\", train_df['img_path'].iloc[0])\n",
        "# print(\"File exists?\", os.path.exists(train_df['img_path'].iloc[0]))"
      ],
      "metadata": {
        "id": "JgjZbW7TiS9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eF_N9_X2i9gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Set epoch to 1\n",
        "# args.epochs = 1\n",
        "# args.device = 1\n",
        "\n",
        "# # BEiT model config\n",
        "# if args.image_pretrained_model == \"beit-base-patch16-224-pt22k-ft22k\":\n",
        "#     img_model_name = \"microsoft/beit-base-patch16-224-pt22k-ft22k\"\n",
        "#     latent_dim = 768\n",
        "\n",
        "# processor = AutoImageProcessor.from_pretrained(img_model_name)\n",
        "\n",
        "# # Load and preprocess data\n",
        "# train_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Bird/data/data/train.csv')\n",
        "# test_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Bird/data/data/test.csv')\n",
        "\n",
        "# train_df[\"img_path\"] = train_df[\"img_path\"].str.replace('./train/', '/content/drive/MyDrive/Colab Notebooks/Bird/data/data/train/')\n",
        "# test_df[\"img_path\"] = test_df[\"img_path\"].str.replace('./test/', '/content/drive/MyDrive/Colab Notebooks/Bird/data/data/test/')\n",
        "# train_df[\"upscale_img_path\"] = train_df[\"upscale_img_path\"].str.replace('./train/', '/content/drive/MyDrive/Colab Notebooks/Bird/data/data/train/')\n",
        "# # Create label mapping\n",
        "# train_labels = train_df[\"label\"]\n",
        "# label_unique = {k:v for k,v in zip(sorted(np.unique(train_labels)), range(len(np.unique(train_labels))))}\n",
        "# train_df[\"label\"] = train_df[\"label\"].apply(lambda x : label_unique[x])\n",
        "\n",
        "# # Initialize CutMix\n",
        "# cutmix = v2.CutMix(num_classes=len(label_unique))\n",
        "\n",
        "# # Define dataset and model classes as in the original code\n",
        "# class ImageDataset(Dataset):\n",
        "#    def __init__(self, df, img_path, is_test=False, transform=None):\n",
        "#        self.df = df\n",
        "#        self.processor = processor\n",
        "#        self.img_path = img_path\n",
        "#        self.is_test = is_test\n",
        "#        self.transform = transform\n",
        "\n",
        "#    def __len__(self):\n",
        "#        return len(self.df)\n",
        "\n",
        "#    def __getitem__(self, idx):\n",
        "#        row = self.df.iloc[idx]\n",
        "#        print(f\"Trying to load image: {row[self.img_path]}\")\n",
        "#        print(f\"File exists: {os.path.exists(row[self.img_path])}\")\n",
        "#        image = cv2.imread(row[self.img_path])\n",
        "#        if image is None:\n",
        "#            print(f\"Failed to load image at index {idx}\")\n",
        "#        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "#        if not self.is_test:\n",
        "#            encoding = self.processor(images=image, return_tensors=\"pt\")\n",
        "#            encoding[\"labels\"] = torch.tensor(row['label'], dtype=torch.long)\n",
        "#            for k,v in encoding.items():\n",
        "#                encoding[k] = v.squeeze()\n",
        "#            return encoding\n",
        "\n",
        "#        encoding = self.processor(images=image, return_tensors=\"pt\")\n",
        "#        for k,v in encoding.items():\n",
        "#            encoding[k] = v.squeeze()\n",
        "#        return encoding\n",
        "\n",
        "# class ImageModel(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.model = AutoModel.from_pretrained(img_model_name)\n",
        "#         self.clf = nn.Linear(latent_dim, len(label_unique))\n",
        "\n",
        "#     def forward(self, inputs):\n",
        "#         enc = self.model(inputs)\n",
        "#         x = enc.pooler_output\n",
        "#         outputs = self.clf(x)\n",
        "#         return outputs\n",
        "\n",
        "# class ImageClassifier(pl.LightningModule):\n",
        "#     def __init__(self, backbone, args):\n",
        "#         super().__init__()\n",
        "#         self.backbone = backbone\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         return self.backbone(x)\n",
        "\n",
        "#     def step(self, batch):\n",
        "#         x = batch[\"pixel_values\"]\n",
        "#         y = batch[\"labels\"]\n",
        "#         y_hat = self.forward(x)\n",
        "#         loss = nn.CrossEntropyLoss()(y_hat, y)\n",
        "#         return loss, y, y_hat\n",
        "\n",
        "#     def training_step(self, batch, batch_idx):\n",
        "#         loss_ce, y, y_hat = self.step(batch)\n",
        "#         loss_cos = nn.CosineEmbeddingLoss()(\n",
        "#             y_hat, y, torch.Tensor([1]).to(self.device)\n",
        "#         )\n",
        "#         loss = loss_ce + loss_cos\n",
        "#         self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "#         return loss\n",
        "\n",
        "#     def validation_step(self, batch, batch_idx):\n",
        "#         loss_ce, y, y_hat = self.step(batch)\n",
        "#         loss_cos = nn.CosineEmbeddingLoss()(\n",
        "#             y_hat, F.one_hot(y.long(), len(label_unique)), torch.Tensor([1]).to(self.device)\n",
        "#         )\n",
        "#         loss = loss_ce + loss_cos\n",
        "#         f1 = f1_score(y_hat.max(dim=1)[1].cpu().numpy(), y.cpu().numpy(), average='macro')\n",
        "#         self.log('val_loss', loss, on_epoch=True, prog_bar=True)\n",
        "#         self.log(\"val_f1\", f1, on_epoch=True, prog_bar=True)\n",
        "#         return loss\n",
        "\n",
        "#     def configure_optimizers(self):\n",
        "#         optimizer = torch.optim.AdamW(self.parameters(), lr=args.learning_rate)\n",
        "#         scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "#             optimizer=optimizer,\n",
        "#             T_max=args.epochs//2,\n",
        "#             eta_min=args.learning_rate//10,\n",
        "#         )\n",
        "#         return [optimizer], [scheduler]\n",
        "\n",
        "# # Training setup and execution\n",
        "# def collate_fn(batch):\n",
        "#     data = default_collate(batch)\n",
        "#     data = cutmix(data['pixel_values'], data['labels'])\n",
        "#     return {'pixel_values': data[0], 'labels': data[1]}\n",
        "\n",
        "# val_f1_list = []\n",
        "# preds_list = []\n",
        "\n",
        "# skf = StratifiedKFold(n_splits=args.cv, shuffle=True, random_state=args.seed)\n",
        "\n",
        "# for i, (train_index, val_index) in enumerate(skf.split(train_df, train_df[\"label\"])):\n",
        "#     temp_df = train_df.iloc[train_index]\n",
        "#     val_df = train_df.iloc[val_index]\n",
        "\n",
        "#     train_ds = ImageDataset(temp_df, \"img_path\", is_test=False) + ImageDataset(temp_df, \"upscale_img_path\", is_test=False)\n",
        "#     val_ds = ImageDataset(val_df, \"img_path\", is_test=False)\n",
        "#     test_ds = ImageDataset(test_df, \"img_path\", is_test=True)\n",
        "\n",
        "#     train_dataloader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, collate_fn=collate_fn)\n",
        "#     val_dataloader = DataLoader(val_ds, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)\n",
        "#     test_dataloader = DataLoader(test_ds, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)\n",
        "\n",
        "#     model = ImageClassifier(ImageModel(), args)\n",
        "#     callbacks = [pl.callbacks.ModelCheckpoint(dirpath=\"saved/\", filename=f\"{args.image_pretrained_model}_{i}\", monitor=\"val_f1\", mode=\"max\")]\n",
        "\n",
        "#     trainer = pl.Trainer(\n",
        "#         max_epochs=args.epochs,\n",
        "#         accelerator=\"auto\",\n",
        "#         callbacks=callbacks,\n",
        "#         precision=args.mixed_precision,\n",
        "#         devices=args.device\n",
        "#     )\n",
        "\n",
        "#     trainer.fit(model, train_dataloader, val_dataloader)\n",
        "\n",
        "#     # Load best checkpoint and make predictions\n",
        "#     ckpt = torch.load(f\"saved/{args.image_pretrained_model}_{i}.ckpt\", map_location=device)\n",
        "#     model.load_state_dict(ckpt['state_dict'])\n",
        "\n",
        "#     eval_dict = trainer.validate(model, dataloaders=val_dataloader)[0]\n",
        "#     val_f1_list.append(eval_dict[\"val_f1\"])\n",
        "\n",
        "#     y_preds = trainer.predict(model, dataloaders=test_dataloader)\n",
        "#     preds_list.append(np.vstack(y_preds))\n",
        "\n",
        "# # Calculate final predictions and create submission\n",
        "# val_f1_mean = np.mean(val_f1_list)\n",
        "# print(f\"Validation F1 Mean: {val_f1_mean}\")\n",
        "\n",
        "# y_pred = np.mean(preds_list, axis=0)\n",
        "# preds = y_pred.argmax(axis=1)\n",
        "\n",
        "# label_decoder = {val:key for key, val in label_unique.items()}\n",
        "# result = [label_decoder[pred] for pred in preds]\n",
        "\n",
        "# submit = pd.read_csv(os.path.join(BASE_PATH, 'sample_submission.csv'))\n",
        "# submit[\"label\"] = result\n",
        "# submit.to_csv(f'{args.image_pretrained_model}.csv', index=False)"
      ],
      "metadata": {
        "id": "6slU0Soafn1S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}